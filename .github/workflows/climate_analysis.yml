name: Urban Climate Resilience Analysis

on:
  schedule:
    # Run daily at 2 AM UTC (adjust for your timezone)
    - cron: '0 2 * * *'
  # Also allow manual triggers
  workflow_dispatch:
  # Run on pushes to main branch
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements.txt'

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  # Parallel job for dependency caching
  cache-dependencies:
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.value }}
    steps:
      - name: Generate cache key
        id: cache-key
        run: |
          echo "value=${{ hashFiles('requirements.txt') }}-${{ github.sha }}" >> $GITHUB_OUTPUT

  # Parallel analysis jobs
  climate-analysis-baseline:
    needs: cache-dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev libatlas-base-dev liblapack-dev
        sudo apt-get remove -y fonts-noto-color-emoji || true
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ needs.cache-dependencies.outputs.cache-key }}
        restore-keys: |
          ${{ needs.cache-dependencies.outputs.cache-key }}
          ${{ hashFiles('requirements.txt') }}-
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install psutil memory-profiler joblib
    
    - name: Create results directory
      run: |
        mkdir -p results/$(date +%Y-%m-%d)
        echo "RESULTS_DIR=results/$(date +%Y-%m-%d)" >> $GITHUB_ENV
    
    - name: Run baseline analysis
      run: |
        export MPLBACKEND=Agg
        export MPLCONFIGDIR=/tmp
        export OMP_NUM_THREADS=2
        export MKL_NUM_THREADS=2
        export OPENBLAS_NUM_THREADS=2
        export VECLIB_MAXIMUM_THREADS=2
        export PYTHONMALLOC=malloc
        export PYTHONUNBUFFERED=1
        
        python auto_run.py --analysis-type baseline 2>&1 | tee ${{ env.RESULTS_DIR }}/baseline_log.txt
      env:
        GITHUB_ACTIONS: true
        PYTHONPATH: ${{ github.workspace }}
        QUICK_MODE: false
        MAX_TIME: 3600
        N_SAMPLES: 500
        SIMULATION_DAYS: 365
      timeout-minutes: 60
    
    - name: Upload baseline results
      uses: actions/upload-artifact@v4
      with:
        name: baseline-analysis-${{ github.run_number }}
        path: results/
        retention-days: 30
        compression-level: 6

  climate-analysis-sensitivity:
    needs: cache-dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev libatlas-base-dev liblapack-dev
        sudo apt-get remove -y fonts-noto-color-emoji || true
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ needs.cache-dependencies.outputs.cache-key }}
        restore-keys: |
          ${{ needs.cache-dependencies.outputs.cache-key }}
          ${{ hashFiles('requirements.txt') }}-
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install psutil memory-profiler joblib
    
    - name: Create results directory
      run: |
        mkdir -p results/$(date +%Y-%m-%d)
        echo "RESULTS_DIR=results/$(date +%Y-%m-%d)" >> $GITHUB_ENV
    
    - name: Run sensitivity analysis
      run: |
        export MPLBACKEND=Agg
        export MPLCONFIGDIR=/tmp
        export OMP_NUM_THREADS=2
        export MKL_NUM_THREADS=2
        export OPENBLAS_NUM_THREADS=2
        export VECLIB_MAXIMUM_THREADS=2
        export PYTHONMALLOC=malloc
        export PYTHONUNBUFFERED=1
        
        python auto_run.py --analysis-type sensitivity 2>&1 | tee ${{ env.RESULTS_DIR }}/sensitivity_log.txt
      env:
        GITHUB_ACTIONS: true
        PYTHONPATH: ${{ github.workspace }}
        QUICK_MODE: false
        MAX_TIME: 3600
        N_SAMPLES: 1000
        SIMULATION_DAYS: 365
      timeout-minutes: 60
    
    - name: Upload sensitivity results
      uses: actions/upload-artifact@v4
      with:
        name: sensitivity-analysis-${{ github.run_number }}
        path: results/
        retention-days: 30
        compression-level: 6

  climate-analysis-uncertainty:
    needs: cache-dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev libatlas-base-dev liblapack-dev
        sudo apt-get remove -y fonts-noto-color-emoji || true
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ needs.cache-dependencies.outputs.cache-key }}
        restore-keys: |
          ${{ needs.cache-dependencies.outputs.cache-key }}
          ${{ hashFiles('requirements.txt') }}-
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install psutil memory-profiler joblib
    
    - name: Create results directory
      run: |
        mkdir -p results/$(date +%Y-%m-%d)
        echo "RESULTS_DIR=results/$(date +%Y-%m-%d)" >> $GITHUB_ENV
    
    - name: Run uncertainty analysis
      run: |
        export MPLBACKEND=Agg
        export MPLCONFIGDIR=/tmp
        export OMP_NUM_THREADS=2
        export MKL_NUM_THREADS=2
        export OPENBLAS_NUM_THREADS=2
        export VECLIB_MAXIMUM_THREADS=2
        export PYTHONMALLOC=malloc
        export PYTHONUNBUFFERED=1
        
        python auto_run.py --analysis-type uncertainty 2>&1 | tee ${{ env.RESULTS_DIR }}/uncertainty_log.txt
      env:
        GITHUB_ACTIONS: true
        PYTHONPATH: ${{ github.workspace }}
        QUICK_MODE: false
        MAX_TIME: 3600
        N_SAMPLES: 800
        SIMULATION_DAYS: 365
      timeout-minutes: 60
    
    - name: Upload uncertainty results
      uses: actions/upload-artifact@v4
      with:
        name: uncertainty-analysis-${{ github.run_number }}
        path: results/
        retention-days: 30
        compression-level: 6

  climate-analysis-control:
    needs: cache-dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev libatlas-base-dev liblapack-dev
        sudo apt-get remove -y fonts-noto-color-emoji || true
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ needs.cache-dependencies.outputs.cache-key }}
        restore-keys: |
          ${{ needs.cache-dependencies.outputs.cache-key }}
          ${{ hashFiles('requirements.txt') }}-
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install psutil memory-profiler joblib
    
    - name: Create results directory
      run: |
        mkdir -p results/$(date +%Y-%m-%d)
        echo "RESULTS_DIR=results/$(date +%Y-%m-%d)" >> $GITHUB_ENV
    
    - name: Run optimal control analysis
      run: |
        export MPLBACKEND=Agg
        export MPLCONFIGDIR=/tmp
        export OMP_NUM_THREADS=2
        export MKL_NUM_THREADS=2
        export OPENBLAS_NUM_THREADS=2
        export VECLIB_MAXIMUM_THREADS=2
        export PYTHONMALLOC=malloc
        export PYTHONUNBUFFERED=1
        
        python auto_run.py --analysis-type control 2>&1 | tee ${{ env.RESULTS_DIR }}/control_log.txt
      env:
        GITHUB_ACTIONS: true
        PYTHONPATH: ${{ github.workspace }}
        QUICK_MODE: false
        MAX_TIME: 3600
        N_SAMPLES: 300
        SIMULATION_DAYS: 365
      timeout-minutes: 60
    
    - name: Upload control results
      uses: actions/upload-artifact@v4
      with:
        name: control-analysis-${{ github.run_number }}
        path: results/
        retention-days: 30
        compression-level: 6

  # Combine results job
  combine-results:
    needs: [climate-analysis-baseline, climate-analysis-sensitivity, climate-analysis-uncertainty, climate-analysis-control]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts/
    
    - name: Combine and commit results
      run: |
        # Create combined results directory
        mkdir -p combined_results/$(date +%Y-%m-%d)
        
        # Copy all results
        find artifacts/ -name "*.png" -exec cp {} combined_results/$(date +%Y-%m-%d)/ \;
        find artifacts/ -name "*.txt" -exec cp {} combined_results/$(date +%Y-%m-%d)/ \;
        find artifacts/ -name "*.json" -exec cp {} combined_results/$(date +%Y-%m-%d)/ \;
        
        # Create summary report
        echo "# Combined Climate Analysis Results - $(date)" > combined_results/$(date +%Y-%m-%d)/README.md
        echo "" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "## Analysis Components" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "- Baseline System Analysis" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "- Sensitivity Analysis" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "- Uncertainty Quantification" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "- Optimal Control Analysis" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "" >> combined_results/$(date +%Y-%m-%d)/README.md
        echo "## Generated Files" >> combined_results/$(date +%Y-%m-%d)/README.md
        ls -la combined_results/$(date +%Y-%m-%d)/ >> combined_results/$(date +%Y-%m-%d)/README.md
        
        # Commit results
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add combined_results/
        git diff --staged --quiet || git commit -m "ðŸ¤– Combined climate analysis results - $(date '+%Y-%m-%d %H:%M')"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Create issue on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'ðŸš¨ Climate Analysis Failed - ' + new Date().toISOString().split('T')[0],
            body: `The automated climate analysis failed on ${new Date().toISOString()}.
            
            **Run Details:**
            - Run ID: ${{ github.run_id }}
            - Run Number: ${{ github.run_number }}
            - Commit: ${{ github.sha }}
            - Workflow: ${{ github.workflow }}
            
            **Parallel Jobs Status:**
            - Baseline: ${{ needs.climate-analysis-baseline.result }}
            - Sensitivity: ${{ needs.climate-analysis-sensitivity.result }}
            - Uncertainty: ${{ needs.climate-analysis-uncertainty.result }}
            - Control: ${{ needs.climate-analysis-control.result }}
            
            **Logs:**
            - [View workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            Please investigate the failure and take appropriate action.`
          })
