name: Urban Climate Resilience Analysis

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements.txt'
      - '.github/workflows/**'

permissions:
  contents: write

jobs:
  # Quick test to ensure basic functionality
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run quick test
      run: python test_quick_run.py
      env:
        MPLBACKEND: Agg
        QUICK_MODE: true

  # Main analysis job
  analysis:
    needs: test
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        scenario: ['baseline', 'heatwave', 'extreme']
      fail-fast: false
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install psutil memory-profiler
    
    - name: Create results directory
      run: |
        mkdir -p results/${{ matrix.scenario }}
        echo "RESULTS_DIR=results/${{ matrix.scenario }}" >> $GITHUB_ENV
    
    - name: Run ${{ matrix.scenario }} analysis
      run: |
        python main.py \
          --analysis-type ${{ matrix.scenario }} \
          --output-dir ${{ env.RESULTS_DIR }}
      env:
        MPLBACKEND: Agg
        PYTHONUNBUFFERED: 1
        OMP_NUM_THREADS: 2
        MAX_TIME: 1800
        N_SAMPLES: 200
        SIMULATION_DAYS: 180
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: results-${{ matrix.scenario }}
        path: ${{ env.RESULTS_DIR }}
        retention-days: 30

  # Combine results and generate report
  report:
    needs: analysis
    runs-on: ubuntu-latest
    if: always()
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: combined_results
    
    - name: Generate summary report
      run: |
        echo "# Climate Resilience Analysis Report" > REPORT.md
        echo "Generated on: $(date)" >> REPORT.md
        echo "" >> REPORT.md
        
        for scenario in baseline heatwave extreme; do
          if [ -d "combined_results/results-$scenario" ]; then
            echo "## $scenario Scenario" >> REPORT.md
            echo "- ✅ Analysis completed" >> REPORT.md
            ls -la combined_results/results-$scenario/*.png 2>/dev/null | wc -l | xargs -I {} echo "- {} visualizations generated" >> REPORT.md
            echo "" >> REPORT.md
          else
            echo "## $scenario Scenario" >> REPORT.md
            echo "- ❌ Analysis failed or incomplete" >> REPORT.md
            echo "" >> REPORT.md
          fi
        done
        
        echo "## Artifacts" >> REPORT.md
        echo "Results are available as workflow artifacts for 30 days." >> REPORT.md
    
    - name: Upload report
      uses: actions/upload-artifact@v4
      with:
        name: analysis-report
        path: |
          REPORT.md
          combined_results/**/*.png
        retention-days: 30

  # Full analysis (weekly)
  full-analysis:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install psutil memory-profiler joblib
    
    - name: Run full analysis
      run: |
        python main.py \
          --analysis-type full \
          --parallel \
          --output-dir results/full
      env:
        MPLBACKEND: Agg
        PYTHONUNBUFFERED: 1
        OMP_NUM_THREADS: 4
        MAX_TIME: 7200
        N_SAMPLES: 500
        SIMULATION_DAYS: 365
    
    - name: Create release
      if: success()
      run: |
        TAG="v$(date +%Y.%m.%d)"
        echo "Creating release $TAG"
        echo "TAG=$TAG" >> $GITHUB_ENV
    
    - name: Upload full results
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: full-analysis-results
        path: results/full
        retention-days: 90
